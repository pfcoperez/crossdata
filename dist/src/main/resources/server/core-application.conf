################################
#                              #
#      Catalog options         #
#                              #
################################
crossdata-core.external.config.resource = "core-application.conf"
crossdata-core.external.config.filename = "/etc/sds/crossdata/server/core-application.conf"
## Pluggable catalog (it has to extend org.apache.spark.sql.crossdata.catalog.XDCatalog)
## If there is no catalog class setted, DerbyCatalog will be used

crossdata-core.catalog.caseSensitive = true

#JDBC parameters

####### Example JDBC MySQL ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.MySQLCatalog"
#crossdata-core.catalog.jdbc.driver = "org.mariadb.jdbc.Driver"
#crossdata-core.catalog.jdbc.url = "jdbc:mysql://127.0.0.1:3306/"
#crossdata-core.catalog.jdbc.db.name = "crossdata"
#crossdata-core.catalog.jdbc.db.table = "crossdataTables"
#crossdata-core.catalog.jdbc.db.view = "crossdataViews"
#crossdata-core.catalog.jdbc.db.user = "root"
#crossdata-core.catalog.jdbc.db.pass = "stratio"


####### PostgreSQL ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.PostgreSQLCatalog"
#crossdata-core.catalog.jdbc.driver = "org.postgresql.Driver"
#crossdata-core.catalog.jdbc.url = "jdbc:postgresql://127.0.0.1:5432/"
#crossdata-core.catalog.jdbc.db.name = "crossdata"
#crossdata-core.catalog.jdbc.db.table = "crossdataTables"
#crossdata-core.catalog.jdbc.db.view = "crossdataViews"
#crossdata-core.catalog.jdbc.db.user = "postgres"
#crossdata-core.catalog.jdbc.db.pass = "postgres"


####### Zookeeper Catalog Configuration ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.ZookeeperCatalog"
#crossdata-core.catalog.zookeeper.connectionString = "localhost:2181"
#crossdata-core.catalog.zookeeper.connectionTimeout = 15000
#crossdata-core.catalog.zookeeper.sessionTimeout = 60000
#crossdata-core.catalog.zookeeper.retryAttempts = 5
#crossdata-core.catalog.zookeeper.retryInterval = 10000



#####################################
#                                   #
#      Streaming configuration      #
#                                   #
#####################################

################################################################################
#  !!WARNING!! Uncomment streaming config in order to use streaming features   #
################################################################################

//####### StreamingCatalog ###########
//crossdata-core.streaming.catalog.class="org.apache.spark.sql.crossdata.catalog.ZookeeperStreamingCatalog"
//crossdata-core.streaming.catalog.zookeeper.connectionString = "localhost:2181"
//crossdata-core.streaming.catalog.zookeeper.connectionTimeout = 15000
//crossdata-core.streaming.catalog.zookeeper.sessionTimeout = 60000
//crossdata-core.streaming.catalog.zookeeper.retryAttempts = 5
//crossdata-core.streaming.catalog.zookeeper.retryInterval = 10000
//
//
//
//####### KafkaReceiverOptions ###########
//crossdata-core.streaming.receiver.zk.connection = "localhost:2181"
//crossdata-core.streaming.receiver.kafka.connection = "localhost:9092"
//crossdata-core.streaming.receiver.storageLevel = "MEMORY_AND_DISK_SER"
//#crossdata-core.streaming.receiver.kafka.numPartitions = "1"
//#crossdata-core.streaming.receiver.kafka.options.someKey = "someValue"
//
//####### StreamingOptions ###########
//crossdata-core.streaming.atomicWindow = "5"
//crossdata-core.streaming.maxWindow= "10"
//crossdata-core.streaming.outputFormat = "JSON"
//#The checkpoint directory will be checkpointDirectory/ephemeralTableName
//crossdata-core.streaming.checkpointDirectory = "/user/stratio/crossdata"
//crossdata-core.streaming.sparkHome = "/opt/sds/spark"
//crossdata-core.streaming.appJar = "/etc/sds/crossdata/lib/crossdata-streaming-${project.version}-jar-with-dependencies.jar"
//#crossdata-core.streaming.jars = []
//
//
//####### SparkOptions ###########
//crossdata-core.streaming.spark.master = "spark://localhost:7077"
//#crossdata-core.streaming.spark.driver.memory = 512M
//#crossdata-core.streaming.spark.executor.memory = 512M
//crossdata-core.streaming.spark.cores.max = 2
//crossdata-core.streaming.spark.stopGracefully = true
//crossdata-core.streaming.spark.eventLog.enabled = false
//crossdata-core.streaming.spark.eventLog.dir = "/user/stratio/crossdata"
//#crossdata-core.streaming.spark.executor.cores
//
//
//####### Particular formats ###########
//# Each connection has three elements separated by ':' and if more connections are needed they have to be added between ','.
//#crossdata-core.streaming.kafka.connection = "HOST:CONSUMER_PORT:PRODUCER_PORT,HOST:CONSUMER_PORT:PRODUCER_PORT"
//
//# Each topic has two elements separated by ':' and if more topics are needed they have to be added between ','.
//#crossdata-core.streaming.kafka.topic = "TOPIC_NAME:NUM_PARTITIONS,TOPIC_NAME:NUM_PARTITIONS"
//
//# options not mandatory like queryoptions, kafka.options and sparkoptions are passed to a config Map. It is needed to add a key after the parameter name
//#crossdata-core.streaming.kafka.options.someKey = "someKafkaValue"
//#crossdata-core.streaming.spark.someKey = "someSparkValue"
