crossdata-core.external.config.resource = "core-application.conf"
crossdata-core.external.config.filename = "/etc/sds/crossdata/server/core-application.conf"
crossdata-core.external.config.filename = ${?crossdata_core_external_config_filename}
################################
#                              #
#       Launcher options       #
#                              #
################################
crossdata-core.launcher.sparkHome=/opt/sds/spark
crossdata-core.launcher.sparkHome=${?crossdata_core_launcher_spark_home}

################################
#                              #
#      Catalog options         #
#                              #
################################
## Pluggable catalog (it has to extend org.apache.spark.sql.crossdata.catalog.XDCatalog)
## If there is no catalog class setted, DerbyCatalog will be used

#JDBC parameters

####### Example JDBC MySQL ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.MySQLCatalog"
#crossdata-core.catalog.jdbc.driver = "org.mariadb.jdbc.Driver"
#crossdata-core.catalog.jdbc.url = "jdbc:mysql://127.0.0.1:3306/"
#crossdata-core.catalog.jdbc.db.name = "crossdata"
#crossdata-core.catalog.jdbc.db.user = "root"
#crossdata-core.catalog.jdbc.db.pass = "stratio"
#crossdata-core.catalog.prefix = "crossdataCluster"


####### PostgreSQL ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.PostgreSQLCatalog"
#crossdata-core.catalog.jdbc.driver = "org.postgresql.Driver"
#crossdata-core.catalog.jdbc.url = "jdbc:postgresql://127.0.0.1:5432/"
#crossdata-core.catalog.jdbc.db.user = "postgres"
#crossdata-core.catalog.jdbc.db.pass = "postgres"
#crossdata-core.catalog.prefix = "crossdataCluster"


####### Zookeeper Catalog Configuration ###########
#crossdata-core.catalog.class = "org.apache.spark.sql.crossdata.catalog.ZookeeperCatalog"
#crossdata-core.catalog.zookeeper.connectionString = "localhost:2181"
#crossdata-core.catalog.zookeeper.connectionTimeout = 15000
#crossdata-core.catalog.zookeeper.sessionTimeout = 60000
#crossdata-core.catalog.zookeeper.retryAttempts = 5
#crossdata-core.catalog.zookeeper.retryInterval = 10000
#crossdata-core.catalog.prefix = "crossdataCluster"

#####################################
#                                   #
#         HDFS config               #
#                                   #
#####################################
crossdata-core.hdfs.user = "stratio"
crossdata-core.hdfs.user = ${?crossdata_hdfs_user}
crossdata-core.hdfs.namenode = "hdfs://127.0.0.1:9000"
crossdata-core.hdfs.namenode = ${?crossdata_hdfs_namenode}

crossdata-core.jars.externalJars = "/opt/sds/crossdata/externalJars"
crossdata-core.jars.externalJars = ${?crossdata_hdfs_externaljars}


#####################################
#                                   #
#      Streaming configuration      #
#                                   #
#####################################

################################################################################
#  !!WARNING!! Uncomment streaming config in order to use streaming features   #
################################################################################

//####### StreamingCatalog ###########
//crossdata-core.streaming.catalog.class="org.apache.spark.sql.crossdata.catalog.ZookeeperStreamingCatalog"
//crossdata-core.streaming.catalog.zookeeper.connectionString = "localhost:2181"
//crossdata-core.streaming.catalog.zookeeper.connectionTimeout = 15000
//crossdata-core.streaming.catalog.zookeeper.sessionTimeout = 60000
//crossdata-core.streaming.catalog.zookeeper.retryAttempts = 5
//crossdata-core.streaming.catalog.zookeeper.retryInterval = 10000
//crossdata-core.streaming.catalog.zookeeper.prefix = "crossdataCluster"
//
//
//
//####### KafkaReceiverOptions ###########
//crossdata-core.streaming.receiver.zk.connection = "localhost:2181"
//crossdata-core.streaming.receiver.kafka.connection = "localhost:9092"
//crossdata-core.streaming.receiver.storageLevel = "MEMORY_AND_DISK_SER"
//#crossdata-core.streaming.receiver.kafka.numPartitions = "1"
//#crossdata-core.streaming.receiver.kafka.options.someKey = "someValue"
//
//####### StreamingOptions ###########
//crossdata-core.streaming.atomicWindow = "5"
//crossdata-core.streaming.maxWindow= "10"
//crossdata-core.streaming.outputFormat = "JSON"
//#The checkpoint directory will be checkpointDirectory/ephemeralTableName
//crossdata-core.streaming.checkpointDirectory = "/var/sds/crossdata"
//crossdata-core.streaming.sparkHome = "/opt/sds/spark"
//crossdata-core.streaming.appJar = "/opt/sds/crossdata/appjar/crossdata-streaming_${scala.binary.version}-${project.version}-jar-with-dependencies.jar"
//#crossdata-core.streaming.jars = []
//
//
//####### SparkOptions ###########
//crossdata-core.streaming.spark.master = "spark://localhost:7077"
//#crossdata-core.streaming.spark.driver.memory = 512M
//#crossdata-core.streaming.spark.executor.memory = 512M
//crossdata-core.streaming.spark.cores.max = 2
//crossdata-core.streaming.spark.stopGracefully = true
//crossdata-core.streaming.spark.eventLog.enabled = false
//crossdata-core.streaming.spark.eventLog.dir = "/var/sds/crossdata"
//#crossdata-core.streaming.spark.executor.cores
//
//
//####### Particular formats ###########
//# Each connection has three elements separated by ':' and if more connections are needed they have to be added between ','.
//#crossdata-core.streaming.kafka.connection = "HOST:CONSUMER_PORT:PRODUCER_PORT,HOST:CONSUMER_PORT:PRODUCER_PORT"
//
//# Each topic has two elements separated by ':' and if more topics are needed they have to be added between ','.
//#crossdata-core.streaming.kafka.topic = "TOPIC_NAME:NUM_PARTITIONS,TOPIC_NAME:NUM_PARTITIONS"
//
//# options not mandatory like queryoptions, kafka.options and sparkoptions are passed to a config Map. It is needed to add a key after the parameter name
//#crossdata-core.streaming.kafka.options.someKey = "someKafkaValue"
//#crossdata-core.streaming.spark.someKey = "someSparkValue"


####################################
#                                  #
#      Security configuration      #
#                                  #
####################################
#crossdata-core.security.manager.class = "org.apache.spark.sql.crossdata.security.DefaultSecurityManager"
#crossdata-core.security.manager.audit = false
#crossdata-core.security.manager.user = "user"
#crossdata-core.security.manager.password = "password"
#crossdata-core.security.manager.session = "sessionId"
